{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPENAI_API_KEY=\"[API_KEY_HERE]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_in=\"/Users/vorsi/Dropbox/bot and agenda-setting/codes and data/reg_table_with_ctrls_bot_prob/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ec658",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bots=pd.read_csv(\"/Users/vorsi/Dropbox/bot and agenda-setting/orsi/bot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1555252",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4623e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_id(row):\n",
    "    return int(row['url'].split(\"user_id=\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bots['user_id']=test_bots.apply(get_user_id,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"\"\"Can you tell me if this Twitter account at the following link \n",
    "     is a human user or a bot: \"\"\"+test_bots['url'][0]}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd594aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c68542",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bots['user_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a single account by screen name\n",
    "#result = bom.check_account('@clayadavis')\n",
    "\n",
    "# Check a single account by id\n",
    "result = bom.check_account(test_bots['user_id'][0])\n",
    "\n",
    "# Check a sequence of accounts\n",
    "#accounts = ['@clayadavis', '@onurvarol', '@jabawack']\n",
    "#for screen_name, result in bom.check_accounts_in(accounts):\n",
    "    # Do stuff with `screen_name` and `result`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f872e9",
   "metadata": {},
   "source": [
    "user: Twitter user object (from the request) plus the language inferred from the majority of tweets\n",
    "\n",
    "raw scores: bot scores in the [0,1] range, both English (using all features) and Universal (using only language-independent features); in each case we have the overall score and the sub-scores for each bot class (see below for subclass names and definitions)\n",
    "\n",
    "display scores: same as raw scores, but in the [0,5] range\n",
    "\n",
    "cap: Complete Automation Probability (CAP) is the conditional probability that accounts with a score equal to or greater than this are automated; based on inferred language\n",
    "\n",
    "Bot types:\n",
    "\n",
    "fake_follower: bots purchased to increase follower counts \n",
    "\n",
    "self_declared: bots from botwiki.org \n",
    "\n",
    "astroturf: manually labeled political bots and accounts involved in follow trains that systematically delete content\n",
    "\n",
    "spammer: accounts labeled as spambots from several datasets\n",
    "\n",
    "financial: bots that post using cashtags\n",
    "\n",
    "other: miscellaneous other bots obtained from manual annotation, user feedback, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9188704",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=[]\n",
    "errrors=[]\n",
    "for user in list(test_bots['user_id']):\n",
    "    try:\n",
    "        result = bom.check_account(user)\n",
    "        R.append(result)\n",
    "    except:\n",
    "        errrors.append(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf296c",
   "metadata": {},
   "source": [
    "Bot scores are displayed on a 0-to-5 scale with zero being most human-like and five being the most bot-like. A score in the middle of the scale is a signal that our classifier is uncertain about the classification. On the Botometer Pro API, this is called display score. The API also provides the raw score in the range 0-1.\n",
    "\n",
    "While bot scores are useful for visualization and behavior analysis, they don't provide enough information by themselves to classify an account. A more meaningful way to interpret a score is to ask: \"What are the chances that an account with a bot score higher than this account is human, or automated?\" To answer this question, the Botometer API provides the so-called CAP, defined as the probability, according to our models, that an account with this score or greater is controlled by software, i.e., is a bot. (For the statisticians, this conditional probability calculation uses Bayes' theorem to take into account an estimate of the overall prevalence of bots, so as to balance false positives with false negatives.)\n",
    "\n",
    "For example, suppose an account has a raw bot score of 0.96/1 (equivalent to 4.8/5 display score on the website) and CAP 90%. This means that 90% of accounts with a raw bot score above 0.96 are labeled as bots, or, as indicated on the website, 10% of accounts with a bot score above 4.8/5 are labeled as humans. In other words, if you use a threshold of 0.96 on the raw bot score (or 4.8 on the display score) to classify accounts as human/bot, you would wrongly classify 10% of accounts as bots -- a false positive rate of 10%.\n",
    "\n",
    "Therefore, if binary classification is necessary, you could set a threshold on the CAP based on a statistical test. You may want the false positive rate to be pretty small, say less than 5%. To this end, you could label accounts with CAP above 95% as bots. Depending on your application, you may want to use a less conservative threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36378018",
   "metadata": {},
   "outputs": [],
   "source": [
    "R[1]['display_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#json_object = json.dumps(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ed5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(R[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#son_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9c868",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Writing to sample.json\n",
    "json_object = json.dumps(R)\n",
    "with open(\"sampled_bots_botometer.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ea976",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800148a",
   "metadata": {},
   "source": [
    "# CHECK OUR BOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b190e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import in bots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ace483",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(len(set(all_users['id']))-2000)*0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25491b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checked_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_users=[int(i['user']['user_data']['id_str']) for i in R]+errrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('sampled_bots_botometer_Jun23.json') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R=[]\n",
    "#errrors=[]\n",
    "count=10\n",
    "for userid in list(all_users['id']):\n",
    "    if userid not in checked_users and count<17250:\n",
    "        checked_users.append(userid)\n",
    "        count+=1\n",
    "        try:\n",
    "            result = bom.check_account(user)\n",
    "            R.append(result)\n",
    "        except:\n",
    "            errrors.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34303fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(R)\n",
    "with open(\"sampled_bots_botometer.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "17260-2980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8443b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bom.wait_on_ratelimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "errrors=[]\n",
    "R=[]\n",
    "for userid in list(all_users['id'])[:15000]:\n",
    "    count+=1\n",
    "    if userid not in checked_users:\n",
    "        if len(R)%1000==0:\n",
    "            print(len(R))\n",
    "        if count%15000==0:\n",
    "            print(count)\n",
    "            json_object = json.dumps(R)\n",
    "            with open(\"sampled_bots_botometer_\"+str(count)+\".json\", \"w\") as outfile:\n",
    "                outfile.write(json_object)\n",
    "            R=[]\n",
    "        try:\n",
    "            result = bom.check_account(userid)\n",
    "            R.append(result)\n",
    "        except:\n",
    "            errrors.append(userid)\n",
    "        checked_users.append(userid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15500617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfefc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_in=\"/Users/vorsi/Dropbox/bot and agenda-setting/codes and data/reg_table_with_ctrls_bot_prob/\"\n",
    "all_users=pd.read_csv(p_in+\"missing_users_botometer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61936bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botometer\n",
    "\n",
    "rapidapi_key = \"3028a43109msh5fa8623a499002dp14b73cjsnd68607e9d83f\"\n",
    "twitter_app_auth = {\n",
    "    'consumer_key': '1w9kQ5nBaPbYLb7euUsCprAhU',\n",
    "    'consumer_secret': 'Toa2Zq9girGmtPpnNbYegn9k4uYEeoV3yMf5LNFLobyh2bpVc9',\n",
    "    'access_token': '443619917-XLzauvkNiYwMhZcug3bbQ2RGXTvyqvQ2JbYq6qxz',\n",
    "    'access_token_secret': 'TTqGTLFhWpY8ItCx0hJr2ZEdd8qypMfmmkbFgYKmVMcVX',\n",
    "  }\n",
    "bom = botometer.Botometer(wait_on_ratelimit=True,\n",
    "                          rapidapi_key=rapidapi_key,\n",
    "                          **twitter_app_auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "count=0\n",
    "errrors=[]\n",
    "R=[]\n",
    "for userid in list(all_users['0']):\n",
    "    count+=1\n",
    "    if len(R)%1000==0:\n",
    "        print(len(R))\n",
    "    if count%5000==0:\n",
    "        print(count)\n",
    "        json_object = json.dumps(R)\n",
    "        with open(\"sampled_bots_botometer_\"+str(count)+\".json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "            R=[]\n",
    "    try:\n",
    "        result = bom.check_account(userid)\n",
    "        R.append(result)\n",
    "    except:\n",
    "        errrors.append(userid)\n",
    "json_object = json.dumps(R)\n",
    "with open(\"sampled_bots_botometer_\"+str(count)+\".json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_object = json.dumps(R)\n",
    "with open(\"sampled_bots_botometer_\"+str(count)+\".json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "errrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf68b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
