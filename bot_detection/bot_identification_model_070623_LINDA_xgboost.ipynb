{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdfe27a-520e-48b2-8820-ed21de54b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb2354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcc275-6242-46dd-ae03-24303cfc40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "#from sklearn import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.layers import Dropout\n",
    "#from keras.layers import Flatten\n",
    "#from keras.metrics import *\n",
    "#import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaae86a-bc8d-4a38-8f86-d457b2461161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926a2b1-5db4-4df2-9926-facadcba45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import rfpimp\n",
    "#from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c36707-0157-40ec-ae12-cb2397ff0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964073a-b5ca-40b0-be2b-97df0684de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6969afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_in=\"/home/lindali/Dropbox/bot and agenda-setting/codes and data/bot_identification_code_and_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_json(p_in+\"training_set/Twibot-20/dev.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f381f844-9f6c-4d63-b38e-83a5a7918cb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a85f2-d21c-4d2b-b348-af3afb38e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in json training set & data preprocessing\n",
    "def json_unifier(file_path, is_bot = None):\n",
    "    with open(file_path) as f:\n",
    "        file = json.loads(f.read())\n",
    "        key_to_extract = list(file[0].keys())[1]\n",
    "        user_dict_list = [i[key_to_extract] for i in file]\n",
    "    df = pd.DataFrame(user_dict_list)\n",
    "    if is_bot is not None:\n",
    "        df['is_bot'] = is_bot\n",
    "    elif file_path != \"./training_set/Twibot-20/train.json\":\n",
    "        identification_path = file_path.replace(\"_tweets.json\", \".tsv\")\n",
    "        tag_df = pd.read_csv(identification_path, sep='\\t', names = ['id','is_bot'])\n",
    "        tag_df['is_bot'] = [1.0 if i == \"bot\" else 0.0 for i in list(tag_df['is_bot'])]\n",
    "        df = pd.merge(df,tag_df,left_on='id',right_on='id', copy = False, suffixes=(None, '_y'))\n",
    "        #df['is_bot'] = df[\"is_bot_y\"]\n",
    "        #df.drop(labels = [\"id_y\", \"is_bot_y\"], axis = 1)\n",
    "        #print(df)\n",
    "    else:\n",
    "        with open(file_path) as f:\n",
    "            file = json.loads(f.read())\n",
    "            key_to_extract_new = list(file[0].keys())[5]\n",
    "            is_bot = [int(i[key_to_extract_new]) for i in file]\n",
    "        df['is_bot'] = is_bot\n",
    "    return df\n",
    "\n",
    "training_set_paths = {p_in+\"training_set/Twibot-20/train.json\":None,\n",
    "                     p_in+\"training_set/verified-2019_tweets.json\":0,\n",
    "                     p_in+\"training_set/vendor-purchased-2019_tweets.json\":1,\n",
    "                     p_in+\"training_set/political-bots-2019_tweets.json\":1,\n",
    "                     p_in+\"training_set/cresci-rtbust-2019_tweets.json\":None,\n",
    "                      p_in+\"training_set/botometer-feedback-2019_tweets.json\":None,\n",
    "                     p_in+\"training_set/botwiki-2019/botwiki-2019_tweets.json\":1\n",
    "                     }\n",
    "all_df = pd.DataFrame()\n",
    "for file,is_bot in training_set_paths.items():\n",
    "    #print(is_bot)\n",
    "    training_df = json_unifier(file, is_bot)\n",
    "    #print(training_df)\n",
    "    all_df = pd.concat([all_df, training_df], ignore_index=True)\n",
    "    #all_df = all_df.append(training_df,ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67c2bf-3ece-4fed-a48a-f2e3489db416",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./training_set/Twibot-20/train.json\"\n",
    "is_bot = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b0335-3b56-40d4-bb9a-3b6f9a35aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv files\n",
    "delete_list = ['timestamp', 'crawled_at', 'updated', 'test_set_1','test_set_2']\n",
    "def csv_unifier(file_path, is_bot = None):\n",
    "    df = pd.read_csv(file_path)\n",
    "    column_list = list(df.columns)\n",
    "    column_list = [i for i in column_list if i not in delete_list]\n",
    "    df = df[column_list]\n",
    "    if is_bot is not None:\n",
    "        df['is_bot'] = is_bot\n",
    "    return df\n",
    "\n",
    "csv_set_paths = {\"./training_set/users_real.csv\":0,\n",
    "            \"./training_set/users.csv\":1,\n",
    "            \"./training_set/users_fake_follower.csv\":1,\n",
    "                 \"./training_set/users_socialbot.csv\":1\n",
    "                }\n",
    "for file, is_bot in csv_set_paths.items():\n",
    "    training_df = csv_unifier(file, is_bot)\n",
    "    all_df = pd.concat([all_df, training_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66eca2d-7eb0-4f1f-95f8-9c54cdec76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(all_df, create_param = 'created_at'):\n",
    "    created_at_dt = pd.to_datetime(all_df[create_param], format = \"%a %b %d %H:%M:%S +0000 %Y \", errors = 'coerce')\n",
    "    created_at_dt_new = pd.to_datetime(all_df[create_param], format = \"%a %b %d %H:%M:%S +0000 %Y\", errors = 'coerce')\n",
    "    created_at_dt = [created_at_dt_new[i] if pd.isnull(created_at_dt[i]) else created_at_dt[i] for i in range(len(created_at_dt))]\n",
    "    all_df['created_at_dt'] = created_at_dt\n",
    "    all_df['user_age'] = [datetime.now() - i for i in all_df['created_at_dt']]\n",
    "    all_df['user_age'] = [i.total_seconds()//3600 for i in all_df['user_age']]\n",
    "    main_traits = ['statuses_count', 'followers_count', 'friends_count', 'favourites_count', 'listed_count']\n",
    "    derived_traits = ['tweet_freq','followers_growth','friends_growth', 'favourites_growth', 'listed_growth']\n",
    "\n",
    "    for i in range(5):\n",
    "        all_df[main_traits[i]] = [int(k) for k in all_df[main_traits[i]]]\n",
    "        all_df[derived_traits[i]] = all_df[main_traits[i]]/all_df['user_age']\n",
    "\n",
    "    all_df['follower_friend_ratio'] = all_df['followers_count']/(all_df['friends_count'] + 1)\n",
    "    all_df['screen_name_length'] = [len(i) for i in all_df['screen_name']]\n",
    "    all_df['digits_in_screen_name'] = [sum(c.isdigit() for c in i) for i in all_df['screen_name']]\n",
    "    all_df['name_length'] = [len(i) if pd.notnull(i) else 0 for i in all_df['name']]\n",
    "    all_df['digits_in_name'] = [sum(c.isdigit() for c in i) if pd.notnull(i) else 0 for i in all_df['name']]\n",
    "    all_df['description_length'] = [len(i) if pd.notnull(i) else 0 for i in all_df['description']]\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00833463-9864-4de6-9e35-094af300ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = generate_features(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1182ef-bb19-4ba4-b72a-7caf71aadb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have much smaller sample Counter({0.0: 9813, 1.0: 14785})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb2798-e6ef-444d-945c-a36d3e2b974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(all_df.is_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c98e7d-93af-42d7-8f29-7913a0de4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['user_age'] = [datetime.now() - i for i in all_df['created_at_dt']]\n",
    "all_df['user_age'] = [i.total_seconds()//3600 for i in all_df['user_age']]\n",
    "main_traits = ['statuses_count', 'followers_count', 'friends_count', 'favourites_count', 'listed_count']\n",
    "derived_traits = ['tweet_freq','followers_growth','friends_growth', 'favourites_growth', 'listed_growth']\n",
    "\n",
    "for i in range(5):\n",
    "    all_df[main_traits[i]] = [int(k) for k in all_df[main_traits[i]]]\n",
    "    all_df[derived_traits[i]] = all_df[main_traits[i]]/all_df['user_age']\n",
    "\n",
    "all_df['follower_friend_ratio'] = all_df['followers_count']/(all_df['friends_count'] + 1)\n",
    "all_df['screen_name_length'] = [len(i) for i in all_df['screen_name']]\n",
    "all_df['digits_in_screen_name'] = [sum(c.isdigit() for c in i) for i in all_df['screen_name']]\n",
    "all_df['name_length'] = [len(i) if pd.notnull(i) else 0 for i in all_df['name']]\n",
    "all_df['digits_in_name'] = [sum(c.isdigit() for c in i) if pd.notnull(i) else 0 for i in all_df['name']]\n",
    "all_df['description_length'] = [len(i) if pd.notnull(i) else 0 for i in all_df['description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcbb7b-f31e-4c60-971d-5eb3416ec546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) statuses count; (2) followers count; (3)\n",
    "#friends count; (4) favorites count; (5) listed count; (6) default profile; (7) geo enabled; (8) profile\n",
    "#use background image; (9) protected; and (10) verified. \n",
    "\n",
    "def get_train_test(df, test_size = 0.3, random_state = 15):\n",
    "    features = ['statuses_count', 'followers_count', \"friends_count\", \"favourites_count\",\"listed_count\",\"default_profile\",\n",
    "               \"geo_enabled\",\"profile_use_background_image\",\n",
    "                \"protected\", \n",
    "                \"verified\",'tweet_freq','followers_growth','friends_growth', 'favourites_growth', 'listed_growth',\n",
    "               'follower_friend_ratio', 'screen_name_length','digits_in_screen_name', \n",
    "               'name_length','digits_in_name', 'description_length']\n",
    "\n",
    "    boolean_features = [\"default_profile\",\"geo_enabled\",\"profile_use_background_image\", \"verified\",\n",
    "                       \"protected\"]\n",
    "    #boolean_features = [\"protected\", \"verified\"]\n",
    "    x_df = df[features]\n",
    "    x_df = x_df.fillna(0.0)\n",
    "    x_df[boolean_features] = x_df[boolean_features].replace(\"True \",1.0)\n",
    "    x_df[boolean_features] = x_df[boolean_features].replace(\"False \",0.0)\n",
    "    x_df = x_df.apply(lambda x: np.asarray(x).astype(np.float32))\n",
    "\n",
    "    y_df = df['is_bot']\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x_df, y_df, test_size = test_size, random_state = random_state)\n",
    "    return xtrain, xtest, ytrain, ytest\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = get_train_test(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed28f3f-1ee5-4f92-a3bd-af9705216c58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22e73b-1573-4051-89ce-55bb9de14fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline: botometre\n",
    "rf_cols = ['statuses_count', 'followers_count', \"friends_count\", \"favourites_count\",\"listed_count\",\"default_profile\",\n",
    "               \"geo_enabled\",\"profile_use_background_image\",\n",
    "                \"protected\", \n",
    "                \"verified\"]\n",
    "xtest_rf = xtest[rf_cols]\n",
    "xtrain_rf = xtrain[rf_cols]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da20a53-64c3-414d-9d44-9def56db1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test1 = {'n_estimators':[i for i in range(10,201,10)]}\n",
    "rf_search1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\n",
    "                                  max_depth=8,max_features='sqrt' ,random_state=10), \n",
    "                       param_grid = rf_test1, scoring='roc_auc',cv=5)\n",
    "rf_search1.fit(xtrain_rf,ytrain)\n",
    "rf_search1.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier(max_depth=8, min_samples_split=100, n_estimators=180,\n",
    "#                       random_state=10)\n",
    "\n",
    "rf_search1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea78df6-bbda-4ed1-b317-8e26a04fe5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_search1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376b25c-2b7e-4c1b-a52a-a6cd757a8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_search1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208463e-76aa-4f75-8349-dfb5884d46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "forest = RandomForestClassifier(n_estimators=150,max_depth=18, max_features='sqrt' ,random_state=10)\n",
    "forest.fit(xtrain,ytrain)\n",
    "forest_result = list(forest.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(ytest, forest_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1132af7-ac17-4a08-b88a-9632bba758eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sklearn.metrics.classification_report(ytest, forest_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2d8b6-7fa7-4918-81e7-a8d02a90e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_10 = RandomForestClassifier(n_estimators=150,max_depth=18, max_features='sqrt' ,random_state=10)\n",
    "forest_10.fit(xtrain_rf,ytrain)\n",
    "forest_10_result = list(forest_10.predict(xtest_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(ytest, forest_10_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d98731-6c2b-4554-a914-6d67f5c4bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(ytest, forest_10_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63c3d3-840e-4b6b-8c3b-869d5f805683",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = forest.predict_proba(xtest_rf)\n",
    "lr_probs = lr_probs[:, 1]\n",
    "lr_auc = roc_auc_score(list(ytest), lr_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(list(ytest), lr_probs)\n",
    "plt.plot(lr_fpr, lr_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3249fe2-9012-4471-979b-739b3753c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "logit = LogisticRegression()\n",
    "logit.fit(xtrain_rf,ytrain)\n",
    "logit_result = list(logit.predict(xtest_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1d2d3-b32c-4330-9267-ada040ee9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(ytest,logit_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edca835-4186-4501-8304-2b60410c7b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435bfee1-ec38-4aab-ad89-6c970506c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(forest, 'random_forest_model_20trait.joblib') \n",
    "joblib.dump(forest_10, 'random_forest_model_20trait.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c441204d-5a10-4695-bf0a-adab20d1e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of metrics\n",
    "# accuracy, percision, recall, f1, sensivity, specificity\n",
    "forest_metric = sklearn.metrics.classification_report(ytest, forest_result,output_dict=True)\n",
    "svm_metric = sklearn.metrics.classification_report(ytest,svm_result,output_dict=True)\n",
    "logit_metric = sklearn.metrics.classification_report(ytest,logit_result,output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6a9c0-4d2b-436f-8cbb-b7a02eb57703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forest_metric)\n",
    "print(svm_metric)\n",
    "print(logit_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf38647-5cbc-4761-adb1-763b77c581ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = ['RF',\"SVM\",\"LOGR\"]\n",
    "df_metric = pd.DataFrame()\n",
    "for index, metrics in enumerate([forest_metric, svm_metric, logit_metric]):\n",
    "    df = pd.DataFrame(metrics).transpose()\n",
    "    df_temp = pd.DataFrame()\n",
    "    df_temp[\"value\"] = df['recall'].iloc[:4]\n",
    "    df_temp['metric'] = ['Specificity','Sensitivity','Balanced Accuracy','Accuracy']\n",
    "    df_temp = df_temp.append({\"metric\":\"F1\", \"value\": float(df.iloc[4,2])}, ignore_index = True)\n",
    "    df_temp['method'] = method[index]\n",
    "    df_metric = df_metric.append(df_temp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae629e-e3c7-455a-b562-00fb732b4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378611c-9155-43a6-bdf1-bb4f7ecfa76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_metric = pd.DataFrame({\"metric\": ['Specificity','Sensitivity','Balanced Accuracy','Accuracy','F1'],\n",
    "                         \"value\":[0.8954,0.8529,0.8911,0.7718, 0.8719]}) # This was what I had before \n",
    "dl_metric['method'] = 'DL'\n",
    "df_metric = df_metric.append(dl_metric, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017ad1c-2e8f-4b18-9cb8-41e1d6d85695",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "\n",
    "plt.figure(figsize=(10, 3.5))\n",
    "ax = sns.barplot(data=df_metric, x='metric', y='value', hue='method',palette=(\"Paired\"))\n",
    "\n",
    "def change_width(ax, new_value) :\n",
    "    for patch in ax.patches :\n",
    "        current_width = patch.get_width()\n",
    "        diff = current_width - new_value\n",
    "\n",
    "        # we change the bar width\n",
    "        patch.set_width(new_value)\n",
    "\n",
    "        # we recenter the bar\n",
    "        patch.set_x(patch.get_x() + diff * .5)\n",
    "\n",
    "change_width(ax, .18)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Value\",fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid()\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "#plt.savefig(\"metric_comparsion_updated_20.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf25b0-facb-4438-8f2f-8786fa8f511f",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179788a8-2d25-4694-a4e5-5e5705c925ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl = xgb.XGBClassifier(booster= \"gbtree\")\n",
    "eval_set = [(xtrain, ytrain), (xtest, ytest)]\n",
    "eval_metric = [\"auc\",\"error\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af38fe-f625-4a99-9a36-89d883367c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl.fit(xtrain, ytrain)\n",
    "ypred = xgb_cl.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c19b1-ab05-41d7-9c3c-2eec0e9bc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(ytest, [1 if i >=0.5 else 0 for i in ypred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72993ecf-4302-4754-bc83-30385b4a465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    " \"learning_rate\" : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    " \"max_depth\" : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\": [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "}\n",
    "\n",
    "xgb_tuning = RandomizedSearchCV(xgb_cl, param_distributions=params, n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5, return_train_score=True)\n",
    "search = xgb_tuning.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01f7ba-2b91-4c50-a94d-2abb558ac8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33c5e2-2d28-4a05-aea5-c1c5120cbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl = xgb.XGBClassifier( learning_rate=0.15,n_estimators=100, colsample_bytree=0.3,gamma=0.4)\n",
    "xgb_cl.fit(xtrain, ytrain)\n",
    "ypred = xgb_cl.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f19ba-f99d-44ca-9cf6-b11b9d5bb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418d26f-3953-4ef1-aa29-989839bea05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score=cross_val_score(xgb_cl,xtrain,ytrain,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171005cc-5d12-487d-b31c-488e8c60e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250a863-6c65-479b-8f2a-4c9720458a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(xgb_cl,  \"/home/lindali/Documents/DPhil studies/thesis_work/bot_identification/xgboost_100623_noseed.joblib\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73746635-46f8-48e4-aecf-9fc8f07b9852",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589d48c-a03f-4f7e-82a3-865e35cc39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validating with other training sets\n",
    "def json_unifier(file_path, is_bot = None):\n",
    "    with open(file_path) as f:\n",
    "        file = json.loads(f.read())\n",
    "    df = pd.DataFrame(file)\n",
    "    #print(df)\n",
    "    identification_path = file_path.replace(\"_tweets.json\", \".tsv\")\n",
    "    tag_df = pd.read_csv(identification_path, sep='\\t', names = ['id','is_bot'])\n",
    "    tag_df['is_bot'] = [1.0 if i == \"bot\" else 0.0 for i in list(tag_df['is_bot'])]\n",
    "    df = pd.merge(df,tag_df,left_on='user_id',right_on='id', copy = False, suffixes=(None, '_y'))\n",
    "        #df['is_bot'] = df[\"is_bot_y\"]\n",
    "        #df.drop(labels = [\"id_y\", \"is_bot_y\"], axis = 1)\n",
    "        #print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5972e2a6-f7bb-4872-8c4f-6183088f2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(midterm_df.is_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105b7ae-969b-4333-badd-d18a21130e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "midterm_df = json_unifier(\"/home/lindali/Documents/DPhil studies/thesis_work/bot_identification/training_set/midterm-2018/midterm-2018_tweets.json\")\n",
    "midterm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6190af-9ee3-480c-a1e7-19f4bda440af",
   "metadata": {},
   "outputs": [],
   "source": [
    "midterm_df = json_unifier(\"/home/lindali/Documents/DPhil studies/thesis_work/bot_identification/training_set/midterm-2018/midterm-2018_tweets.json\")\n",
    "midterm_df = generate_features(midterm_df, 'user_created_at')\n",
    "xtrain_us, xtest_us, ytrain_us, ytest_us = get_train_test(midterm_df,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b5c6d-688d-4afd-9421-9aaddaa6cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(midterm_df[midterm_df.is_bot==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b0ae7-9ba8-49d5-92d2-4daa6d4d721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_result_us = list(forest.predict(xtrain_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc60da-bb69-476f-abbc-58b711fd8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in ytrain_us if i == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a54c5b-c58b-4f26-bc4d-114ce71086b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in forest_result_us if i == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748c178-1a9e-4bac-89da-aa792db0b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(ytrain_us, forest_result_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324c1be-1cc0-46b2-be6c-b5a5c9f988b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_result_us = list(xgb_cl.predict(xtrain_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629ba5d-7443-48f9-a5ba-35fd62cc5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(ytrain_us, xgboost_result_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d66251-39fe-47bd-9465-6b7780378c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(0.8492*0.9767*2/(0.8492+0.9767))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228e649-ba27-4d85-abfe-d906bae6e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_metric = pd.DataFrame({\"metric\": ['Specificity','Sensitivity','Precision','Balanced Accuracy','Accuracy','F1'],\n",
    "                         \"value\":[0.93,0.85,0.98, 0.83,0.91, 0.88]})\n",
    "us_metric_rf = pd.DataFrame({\"metric\": ['Specificity','Sensitivity','Precision','Balanced Accuracy','Accuracy','F1'],\n",
    "                         \"value\":[0.89,0.93,0.97, 0.86,0.86,0.90]})\n",
    "us_metric['method'] = 'RF'\n",
    "us_metric_rf['method'] = 'DL'\n",
    "us_metric = us_metric.append(us_metric_rf, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010d2a4-8256-44ba-b284-9abe95f455a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "\n",
    "plt.figure(figsize=(10, 3.5))\n",
    "ax = sns.barplot(data=us_metric, x='metric', y='value', hue='method')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Value\",fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid()\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"metric_comparsion_rf_dl_updated.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b73b2-5370-473a-809f-839adfd8934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_unifier(file_path, is_bot = None):\n",
    "    with open(file_path) as f:\n",
    "        file = json.loads(f.read())\n",
    "        key_to_extract = list(file[0].keys())[1]\n",
    "        user_dict_list = [i[key_to_extract] for i in file]\n",
    "    df = pd.DataFrame(user_dict_list)\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        file = json.loads(f.read())\n",
    "        key_to_extract_new = list(file[0].keys())[5]\n",
    "        is_bot = [int(i[key_to_extract_new]) for i in file]\n",
    "    df['is_bot'] = is_bot\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7da71e-b0fb-4020-8357-c4db485d4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = json_unifier(\"./training_set/Twibot-20/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e3975-d5a0-4b7c-bf1a-1864bef4fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_twi, xtest_twi, ytrain_twi, ytest_twi = get_train_test(midterm_df,test_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef512dff-4525-4880-8d38-a388a2640a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_result_twi = list(forest.predict(xtrain_twi))\n",
    "print(sklearn.metrics.classification_report(ytrain_twi, forest_result_twi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4ada3-5927-4872-ac5b-3c98c4a5fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(xtrain_twi, ytrain_twi, batch_size = 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
