{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419d9abf-41c1-44a1-9ce8-662aeb6a3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299448a5-e2d9-4f1f-9c01-8d79a7700d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_path = \"./0422_rf_edition/xr_users_classified_0422_wprob.csv\"\n",
    "user_prob_path = \"./0422_rf_edition/xr_users_classified_0704_four_methods_wprob.csv\"\n",
    "tweet_path = \"tweet_table_xr_2019_0621_fixed.csv\"\n",
    "tweet_topic_modelled = \"./NLP/text_classified.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a6e8f-72d8-4ce6-b132-1cd10c183802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c54930dc-85f4-4b98-8e6b-e174c346a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_classification_col = \"is_bot_botometer_0.5\"\n",
    "suffix = \"_botometer_0.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b9609-bc94-47bf-998f-e9ac09439217",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate users w/ bot interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235a3ab-1be4-4609-b782-bfd282db52ac",
   "metadata": {},
   "source": [
    "### Filtering communications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e958e9-c2d4-4c2f-ac76-9ef8e83d6297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143909/1195143438.py:4: DtypeWarning: Columns (46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(tweet_path)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "users = pd.read_csv(user_path, lineterminator='\\n')\n",
    "users_prob = pd.read_csv(user_prob_path, lineterminator='\\n')\n",
    "df = pd.read_csv(tweet_path)\n",
    "tweet_classified = pd.read_csv(tweet_topic_modelled, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d09a29-3c34-4ec7-a598-d1e8533ddaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.merge(users_prob[[\"id\",\"is_bot_xgb\",\"is_bot_xgb_prob\",\"is_bot_botometer\", \"is_bot_botometer_prob\"]], on = \"id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10cd90-0eb3-4447-a7cb-d9de37a9fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out tweet not related to XR like iphone sellers\n",
    "df = df[~df[\"text\"].str.contains(\"(?i)iphone\")]\n",
    "df = df[~df[\"text\"].str.contains(\"(?i)phone\")]\n",
    "df = df[~df[\"text\"].str.contains(\"(?i)max\")]\n",
    "df = df[~df[\"text\"].str.contains(\"(?i)11\")]\n",
    "df = df[~df[\"text\"].str.contains(\"(?i)vr\")]\n",
    "df = df[~df[\"text\"].str.contains(\"(?i)xpel\")]\n",
    "df = df[~df[\"text\"].str.contains(\"(?i)tint\")]\n",
    "#text = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e531f-6ad6-4e40-afd0-d1d10b2006e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy() # keep a copy for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e5b7c-d09f-4ee5-b371-66c9eff598b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out interaction records of humans REPLYING bots\n",
    "df = df[df.referenced_tweets_0_type != \"retweeted\"]\n",
    "df['created_at_dt'] = pd.to_datetime(df.created_at, infer_datetime_format=True)\n",
    "users['created_at_dt'] = pd.to_datetime(users.created_at, infer_datetime_format=True)\n",
    "df = df.merge(users[[bot_classification_col,'id']], how = 'left', left_on = 'author_id', right_on = 'id', copy = False)\n",
    "df = df.merge(tweet_classified, how = 'left', left_on = \"text\", right_on = \"text\", copy = False)\n",
    "\n",
    "df_comm = df.merge(users[[bot_classification_col, 'id']], how = 'left', left_on = 'in_reply_to_user_id', right_on = 'id', suffixes=('', '_reply'))\n",
    "reply_df = df_comm[(df_comm[bot_classification_col+\"_reply\"] == 1) & (df_comm[bot_classification_col] == 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba499217-7935-4865-9a86-39fb605601ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_df.to_csv(f\"./xr2019_user_reply_bots{suffix}.csv\", index = False)\n",
    "df_comm.to_csv(f'./df_comm_edges{suffix}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff95300-e19b-4b37-b497-35476c6e4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_post_id = [i if i is not None else j for i,j in zip(df_bot_reply.referenced_tweets_0_id, df_bot_reply.referenced_tweets_1_id)]\n",
    "bot_post_id = [str(int(i)) for i in bot_post_id if str(i) != \"nan\"] # Saving the ids of bot posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f38793-6a52-4577-be04-0848dc92a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./bot_conversation_id.txt', 'w') as f:\n",
    "    for line in bot_post_id:\n",
    "        f.write(str(line))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e379e2aa-161e-4db5-b4af-bc36fdb63b46",
   "metadata": {},
   "source": [
    "### Generating sample for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ba759-04f0-4bcc-b48c-be54f2b9b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 60 day time range before & after interaction for data collection\n",
    "user_time = users.merge(reply_df[[\"author_id\", \"created_at\", \"text\"]], how = 'inner', left_on = \"id\", right_on = \"author_id\", copy = False)\n",
    "user_time = user_time[['author_id','created_at_x', 'created_at_y', 'text']]\n",
    "user_time.columns = ['author_id', 'user_created_at', 'interaction_at', 'text']\n",
    "user_time = user_time.drop_duplicates(subset = ['author_id'])\n",
    "user_time['user_created_at'] = pd.to_datetime(user_time.user_created_at, infer_datetime_format=True)\n",
    "user_time['interaction_at'] = pd.to_datetime(user_time.interaction_at, infer_datetime_format=True)\n",
    "time_window = timedelta(days = 30)\n",
    "user_time['time_start'] = user_time.interaction_at - time_window\n",
    "user_time['time_end'] = user_time.interaction_at + time_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9679ec4-596d-4e30-a1f6-8b8653749ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_time['time_start_str'] = [i.strftime(\"%Y-%m-%dT%H:%M:%SZ\") for i in user_time.time_start]\n",
    "user_time['time_end_str'] = [i.strftime(\"%Y-%m-%dT%H:%M:%SZ\") for i in user_time.time_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde38bcb-e3b3-474d-a638-0441240d02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_time.to_csv(f\"./matching_user_data_collection_xr2019{suffix}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6525c9f6-c757-4087-b50c-887e5d3703f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating matched users who do not have direct interaction with bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886488b-7cc8-484a-a948-f1f925853309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ab92d-b083-42c6-87c8-f756a5438365",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_df_short = reply_df[[\"author_id\", \"conversation_id\", \"created_at\"]]\n",
    "df['created_at_dt'] = pd.to_datetime(df.created_at, infer_datetime_format=True)\n",
    "df = df.merge(users[[bot_classification_col,'id']], how = 'left', left_on = 'author_id', right_on = 'id', copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd803442-bd23-43e7-82a7-a82360f86b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[bot_classification_col] == 0) & (df.referenced_tweets_0_type != \"replied_to\")]\n",
    "reply_df_short['created_at_dt'] = pd.to_datetime(reply_df_short.created_at, infer_datetime_format=True)\n",
    "df['created_at_rough'] = [i[:-9] for i in df.created_at]\n",
    "reply_df_short['created_at_rough'] = [i[:-9] for i in reply_df_short.created_at]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2f638-b8a1-4bd7-9ded-bc83b93646ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_records = df.merge(reply_df_short, how = 'right', on = \"created_at_rough\", copy = False)\n",
    "matched_records = matched_records[matched_records.author_id_x != matched_records.author_id_y]\n",
    "matched_uids = matched_records[[\"author_id_x\", \"author_id_y\", \"created_at_x\",\"created_at_y\"]]\n",
    "matched_uids.columns = ['matched_user', \"user\", \"interaction_matched\", \"interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc060fa-def9-4b8c-b9c8-80028ef78565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all matched uids without eculid based filterings\n",
    "matched_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a61143-0122-404d-9965-8d4f004dbc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_uids.to_csv(f\"./xr2019_user_matched_rough{suffix}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d1a6a-ddf4-4b78-94d4-365505d7c037",
   "metadata": {},
   "source": [
    "#### Further filtering based on ecudlian distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2aba0-9508-4bd1-b2c2-2fd6fa97742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users[users.created_at != \"0\"]\n",
    "#users.dropna(subset = ['created_at'], inplace = True)\n",
    "#users['created_at_dt'] = pd.to_datetime(users.created_at, format = \"%a %b %d %H:%M:%S +0000 %Y \", errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c3c4f-416f-4fe7-a3c9-a3e3ef1ebc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_uids = matched_uids.drop_duplicates(subset = ['matched_user'])\n",
    "euclid = pd.DataFrame(columns = ['uid', \"matched_uid\", \"euclid\"])\n",
    "cols = ['statuses_count', 'followers_count', 'friends_count',\n",
    "       'favourites_count', 'listed_count', 'followers_growth', 'friends_growth', 'favourites_growth',\n",
    "       'listed_growth', 'follower_friend_ratio']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b039010-4b19-43db-a2c7-6362c961bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = []\n",
    "matched_user = []\n",
    "eculid = []\n",
    "for i in range(matched_uids.shape[0]):\n",
    "    uid = matched_uids.iloc[i].user\n",
    "    matched_uid = matched_uids.iloc[i].matched_user\n",
    "    user_info = users[users.id == uid][cols]\n",
    "    matched_info = users[users.id == matched_uid][cols]\n",
    "    if user_info.shape[0] == 1 and matched_info.shape[0] == 1:\n",
    "        user_info = [np.log(float(i)+1) for i in list(user_info.T.iloc[:,0])]\n",
    "\n",
    "        matched_info = [np.log(float(i) + 1) for i in list(matched_info.T.iloc[:,0])]\n",
    "\n",
    "        X = np.vstack([user_info, matched_info])\n",
    "        euclidean_ = distance.pdist(X)[0]\n",
    "        uids.append(uid)\n",
    "        eculid.append(euclidean_)\n",
    "        matched_user.append(matched_uid)\n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80ac84-0069-49a2-b2cc-a7748b4478e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eculid_df = pd.DataFrame()\n",
    "eculid_df['uid'] = uids\n",
    "eculid_df['eculid'] = eculid\n",
    "eculid_df['matched_uid'] = matched_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48f89a-126a-49bb-bbb8-71a8b9675f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eculid_df.sort_values(by = ['uid', 'eculid'], ascending = [True, False], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6fe0b7-a454-485c-9189-2e33b631b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_with_euclid = eculid_df.merge(matched_uids, right_on = 'matched_user', left_on = 'matched_uid', how = 'left', copy = False)\n",
    "matched_with_euclid.dropna(subset = ['matched_user'], inplace = True)\n",
    "matched_with_euclid['interaction_matched'] = pd.to_datetime(matched_with_euclid.interaction_matched, infer_datetime_format=True)\n",
    "time_window = timedelta(days = 30)\n",
    "matched_with_euclid['time_start'] = matched_with_euclid.interaction_matched - time_window\n",
    "matched_with_euclid['time_end'] = matched_with_euclid.interaction_matched + time_window\n",
    "matched_with_euclid.to_csv(f\".xr2019_user_matched_with_euclid{suffix}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee35cd4-efb2-41b2-a319-96f8aab68031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting first best match\n",
    "firsts = matched_with_euclid.drop_duplicates(subset=['uid'], keep='first')\n",
    "firsts['time_start'] = pd.to_datetime(firsts.time_start, infer_datetime_format=True)\n",
    "firsts['time_end'] = pd.to_datetime(firsts.time_end, infer_datetime_format=True)\n",
    "firsts['time_start_str'] = [i.strftime(\"%Y-%m-%dT%H:%M:%SZ\") for i in seconds.time_start]\n",
    "firsts['time_end_str'] = [i.strftime(\"%Y-%m-%dT%H:%M:%SZ\") for i in seconds.time_end]\n",
    "firsts.to_csv(f\"./xr2019_user_matched_firsts{suffix}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873870c-8be7-400d-84cf-c038a37ab520",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting second best match\n",
    "seconds = matched_with_euclid.groupby('uid').head(2)\n",
    "seconds['time_start'] = pd.to_datetime(seconds.time_start, infer_datetime_format=True)\n",
    "seconds['time_end'] = pd.to_datetime(seconds.time_end, infer_datetime_format=True)\n",
    "seconds['time_start_str'] = [i.strftime(\"%Y-%m-%dT%H:%M:%SZ\") for i in seconds.time_start]\n",
    "seconds['time_end_str'] = [i.strftime(\"%Y-%m-%dT%H:%M:%SZ\") for i in seconds.time_end]\n",
    "seconds.to_csv(f\"./xr2019_user_matched_seconds{suffix}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f7852-50d3-4db7-b01e-c378539172d6",
   "metadata": {},
   "source": [
    "## Collecting bot original tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e01c8a26-04f4-4639-b08a-eadd68c21969",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_replies = pd.read_csv(\"./botometer/xr2019_user_reply_bots_botometer_0.5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff22f930-aa83-45be-83a6-c7f05db29feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI, TwitterOAuth, HydrateType, TwitterPager\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bea406be-f620-4d1e-8a8b-cc83528bb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_token(textfile):\n",
    "    try:\n",
    "        with open(textfile, 'r') as file:\n",
    "            auth = file.readlines()\n",
    "            keys = []\n",
    "            for i in auth:\n",
    "                i = str(i).strip()\n",
    "                keys.append(i)\n",
    "        return keys\n",
    "    except EnvironmentError:\n",
    "        print('Error loading access token from file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2936689-05e3-4ec9-897e-0436792a3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key, consumer_secret, access_token_key, access_token_secret, bearer_token = load_token('/home/lindali/Documents/DPhil studies/thesis_work/twitter_auth')\n",
    "api = TwitterAPI(consumer_key, consumer_secret, access_token_key, access_token_secret, auth_type='oAuth1', api_version='1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67a3e950-4bcf-4ea6-876f-b391ef1a77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = load_token(\"./botometer/bot_conversation_id.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "552faa38-b2ec-483b-b310-a78ba0e981d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = api.request('statuses/show/:' + conversation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdae4015-4266-4dbe-b49e-61bac55d1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3354c5a-b728-4b07-b9ae-5e59fc25d08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'errors': [{'code': 144, 'message': 'No status found with that ID.'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d48772d-2db1-4111-b7e1-9b96a46112da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 conversation collected\n",
      "400 conversation collected\n",
      "800 conversation collected\n",
      "1800 conversation collected\n",
      "2000 conversation collected\n",
      "2200 conversation collected\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bot_original_tweet = []\n",
    "error_ids = []\n",
    "for i,id_ in enumerate(conversation):\n",
    "    #print(id_)\n",
    "    r = api.request('statuses/show/:' + id_)\n",
    "    try:\n",
    "        item = r.json()\n",
    "        #print(item)\n",
    "        #print(item['text'])\n",
    "        #print(item['user']['id_str'])\n",
    "        temp_df_row = {}\n",
    "        temp_df_row['text'] = item['text']\n",
    "        temp_df_row['id'] = item['id']\n",
    "        temp_df_row['author_id'] = item['user']['id_str']\n",
    "        temp_df_row['retweet_count'] = item['retweet_count']\n",
    "        temp_df_row['like_count'] = item['favorite_count']\n",
    "        bot_original_tweet.append(temp_df_row)\n",
    "        if i%200==0:\n",
    "            print(f\"{i} conversation collected\")\n",
    "    except Exception as e:\n",
    "        error_ids.append(i)\n",
    "        #print(e)\n",
    "        pass\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0a007db-750c-4cc9-8254-e17cf3239fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_original_tweet_df = pd.DataFrame.from_records(bot_original_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a010638-ca17-42ba-a108-3d8939378386",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to_bot_and_original_post = reply_to_bot_and_original_post.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3b839f6-f751-468f-bc6d-ad3ce3ed94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to_bot_and_original_post = bot_replies.merge(bot_original_tweet_df, left_on = 'referenced_tweets_0_id', right_on = 'id', suffixes = (\"_original\", \"_reply\"), how = 'left', copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46b74cf8-4ca0-4074-99c5-972cb3e747b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to_bot_and_original_post = reply_to_bot_and_original_post[['text_original','text_reply',\"created_at\", 'author_id_original','author_id_reply',\"id_original\",'id_reply', \n",
    "                                     'retweet_count', 'like_count', 'public_metrics_retweet_count','public_metrics_like_count', \"in_reply_to_user_id\",'topic']]\n",
    "reply_to_bot_and_original_post = reply_to_bot_and_original_post.loc[:,~reply_to_bot_and_original_post.columns.duplicated()].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab9dc599-8d6c-48c4-ab20-dc69cada0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to_bot_and_original_post.columns = ['text', 'original_text', \"created_at\",'author_id', 'bot_id',\n",
    "                            'id', 'original_tweet_id',\"retweet_count_original\", \"like_count_original\",\n",
    "                                          'retweet_count_interaction', 'like_count_interaction',\"in_reply_to_user_id\",'topic'\n",
    "                                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b929090a-0db7-424a-9588-b766f814ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "reply_to_bot_and_original_post['id'] = [str(int(i)) for i in reply_to_bot_and_original_post.id]\n",
    "reply_to_bot_and_original_post['original_tweet_id'] = [i if math.isnan(i) else str(int(i)) for i in reply_to_bot_and_original_post.original_tweet_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fa84665-3a61-4112-9a4f-658d6db6e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to_bot_and_original_post.to_csv(f\"./botometer/bot_original_tweet_updated{suffix}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef2b6b-d955-4680-8843-cb04cecddaef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
